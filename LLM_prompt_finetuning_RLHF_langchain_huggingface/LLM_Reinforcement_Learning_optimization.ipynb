{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d7f10b19-c061-42b2-8b42-e3cbafa3b1da",
      "metadata": {
        "id": "d7f10b19-c061-42b2-8b42-e3cbafa3b1da"
      },
      "source": [
        "# Fine-Tune FLAN-T5 with Reinforcement Learning (PPO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed5003e2-a642-416b-bd3f-93fb339c3a7d",
      "metadata": {
        "tags": [],
        "id": "ed5003e2-a642-416b-bd3f-93fb339c3a7d"
      },
      "source": [
        "# Table of Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6791f449-d1da-461b-9eb7-c6dc6b37b15c",
      "metadata": {
        "tags": [],
        "id": "6791f449-d1da-461b-9eb7-c6dc6b37b15c"
      },
      "source": [
        "- [ 1 - Set up Kernel and Required Dependencies](#1)\n",
        "- [ 2 - Load FLAN-T5 Model, Prepare Reward Model and Toxicity Evaluator](#2)\n",
        "  - [ 2.1 - Load Data and FLAN-T5 Model Fine-Tuned with Summarization Instruction](#2.1)\n",
        "  - [ 2.2 - Prepare Reward Model](#2.2)\n",
        "  - [ 2.3 - Evaluate Toxicity](#2.3)\n",
        "- [ 3 - Perform Fine-Tuning to Detoxify the Summaries](#3)\n",
        "  - [ 3.1 - Initialize `PPOTrainer`](#3.1)\n",
        "  - [ 3.2 - Fine-Tune the Model](#3.2)\n",
        "  - [ 3.3 - Evaluate the Model Quantitatively](#3.3)\n",
        "  - [ 3.4 - Evaluate the Model Qualitatively](#3.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f973f1-f095-4915-86d0-bc16380da22d",
      "metadata": {
        "tags": [],
        "id": "89f973f1-f095-4915-86d0-bc16380da22d"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Set up Kernel and Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8c20bed-6a30-4847-a507-02969ecb4465",
      "metadata": {
        "tags": [],
        "id": "d8c20bed-6a30-4847-a507-02969ecb4465"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
        "from datasets import load_dataset\n",
        "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
        "\n",
        "# trl: Transformer Reinforcement Learning library\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
        "from trl import create_reference_model\n",
        "from trl.core import LengthSampler\n",
        "\n",
        "import torch\n",
        "import evaluate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# tqdm library makes the loops show a smart progress meter.\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76eea84-8e3a-4487-9692-613977e6c8e3",
      "metadata": {
        "id": "b76eea84-8e3a-4487-9692-613977e6c8e3"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Load model to apply the optimization to and an adequate Reward Model to guide the PPO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a5f97d4-ea5f-4072-b5d6-785d1d833ed4",
      "metadata": {
        "tags": [],
        "id": "4a5f97d4-ea5f-4072-b5d6-785d1d833ed4"
      },
      "source": [
        "<a name='2.1'></a>\n",
        "### 2.1 - Load Data and FLAN-T5 Model Fine-Tuned with Summarization Instruction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90dc0211-4032-4967-946d-3a538829d5c9",
      "metadata": {
        "tags": [],
        "id": "90dc0211-4032-4967-946d-3a538829d5c9"
      },
      "source": [
        "Hugging Face dataset [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) and the pre-trained model [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b058b52b-ec4d-4426-8d71-91e898f727f6",
      "metadata": {
        "tags": [],
        "id": "b058b52b-ec4d-4426-8d71-91e898f727f6",
        "outputId": "eefa8834-9835-433c-f56c-e666499747cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "model_name=\"google/flan-t5-small\"\n",
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset_original = load_dataset(huggingface_dataset_name)\n",
        "\n",
        "dataset_original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51469abe-4d72-4093-a6c6-8e04e19f09eb",
      "metadata": {
        "id": "51469abe-4d72-4093-a6c6-8e04e19f09eb",
        "outputId": "6a9c2aa9-d5f9-4cfa-ae18-f6b8d0f1f395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
            "        num_rows: 8017\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
            "        num_rows: 2005\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "def build_dataset(model_name,\n",
        "                  dataset_name,\n",
        "                  input_min_text_length,\n",
        "                  input_max_text_length):\n",
        "\n",
        "    \"\"\"\n",
        "    Preprocess the dataset and split it into train and test parts.\n",
        "\n",
        "    Parameters:\n",
        "    - model_name (str): Tokenizer model name.\n",
        "    - dataset_name (str): Name of the dataset to load.\n",
        "    - input_min_text_length (int): Minimum length of the dialogues.\n",
        "    - input_max_text_length (int): Maximum length of the dialogues.\n",
        "\n",
        "    Returns:\n",
        "    - dataset_splits (datasets.dataset_dict.DatasetDict): Preprocessed dataset containing train and test parts.\n",
        "    \"\"\"\n",
        "\n",
        "    # load dataset (only \"train\" part is enough for this notebook).\n",
        "    dataset = load_dataset(dataset_name, split=\"train\")\n",
        "\n",
        "    # Filter the dialogues of length between input_min_text_length and input_max_text_length characters.\n",
        "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
        "\n",
        "    # Prepare tokenizer. Setting device_map=\"auto\" allows to switch between GPU and CPU automatically.\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
        "\n",
        "    def tokenize(sample):\n",
        "\n",
        "        # Wrap each dialogue with the instruction.\n",
        "        prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{sample[\"dialogue\"]}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
        "\n",
        "        # This must be called \"query\", which is a requirement of our PPO library.\n",
        "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
        "        return sample\n",
        "\n",
        "    # Tokenize each dialogue.\n",
        "    dataset = dataset.map(tokenize, batched=False)\n",
        "    dataset.set_format(type=\"torch\")\n",
        "\n",
        "    # Split the dataset into train and test parts.\n",
        "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
        "\n",
        "    return dataset_splits\n",
        "\n",
        "dataset = build_dataset(model_name=model_name,\n",
        "                        dataset_name=huggingface_dataset_name,\n",
        "                        input_min_text_length=200,\n",
        "                        input_max_text_length=1000)\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f06806-a194-4c14-b64d-e31afd7b658c",
      "metadata": {
        "id": "a1f06806-a194-4c14-b64d-e31afd7b658c"
      },
      "outputs": [],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21e06a57-fb80-4f8c-a967-4c7c42a7bfda",
      "metadata": {
        "tags": [],
        "id": "21e06a57-fb80-4f8c-a967-4c7c42a7bfda"
      },
      "source": [
        "Import the already finetuned with LoRA model from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a94b14-b375-45e7-9e49-a7f2c341b4ff",
      "metadata": {
        "tags": [],
        "id": "a1a94b14-b375-45e7-9e49-a7f2c341b4ff",
        "outputId": "fe1118a4-43b4-49ca-de0f-2afb4bca10e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PEFT model parameters to be updated:\n",
            "\n",
            "trainable model parameters: 1376256\n",
            "all model parameters: 78337408\n",
            "percentage of trainable model parameters: 1.76%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=32, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
        ")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
        "                                              torch_dtype=torch.bfloat16)\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(model,\n",
        "                                       'Desktop/GithubLLMs/LLMs/peft-dialogue-summary-checkpoint-local',\n",
        "                                       lora_config=lora_config,\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       device_map=\"auto\",\n",
        "                                       is_trainable=True)\n",
        "\n",
        "print(f'PEFT model parameters to be updated:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a950ae8a-76b9-4951-9c78-9ac7a6349e17",
      "metadata": {
        "id": "a950ae8a-76b9-4951-9c78-9ac7a6349e17"
      },
      "source": [
        "Use value head to get peft_model into ppo ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e86bab0-6dee-4dff-a754-b584ed962723",
      "metadata": {
        "id": "1e86bab0-6dee-4dff-a754-b584ed962723",
        "outputId": "9492dccc-84cf-41e2-b21e-c1446d618ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO model parameters to be updated (ValueHead + 769 params):\n",
            "\n",
            "trainable model parameters: 1376769\n",
            "all model parameters: 78337921\n",
            "percentage of trainable model parameters: 1.76%\n",
            "\n",
            "ValueHead(\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (summary): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,\n",
        "                                                               torch_dtype=torch.bfloat16,\n",
        "                                                               is_trainable=True)\n",
        "\n",
        "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
        "print(ppo_model.v_head)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2913ef05-737e-4cdf-9bac-467ee6cf9f76",
      "metadata": {
        "id": "2913ef05-737e-4cdf-9bac-467ee6cf9f76"
      },
      "source": [
        "During PPO, only a few parameters will be updated. Specifically, the parameters of the `ValueHead`. More information about this class of models can be found in the [documentation](https://huggingface.co/docs/trl/main/en/models#trl.create_reference_model). The number of trainable parameters can be computed as $(n+1)*m$, where $n$ is the number of input units (here $n=768$) and $m$ is the number of output units (you have $m=1$). The $+1$ term in the equation takes into account the bias term."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c7e2df-0c75-4bd0-bf8d-1f1545ef864e",
      "metadata": {
        "id": "76c7e2df-0c75-4bd0-bf8d-1f1545ef864e"
      },
      "source": [
        "Now create a frozen copy of the PPO which will not be fine-tuned - a reference model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a9b30a-ad14-4189-8088-d4de447fe247",
      "metadata": {
        "id": "18a9b30a-ad14-4189-8088-d4de447fe247",
        "outputId": "d8f63cb7-6d26-4fd8-bd47-59b5b0880492",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference model parameters to be updated:\n",
            "\n",
            "trainable model parameters: 0\n",
            "all model parameters: 78337921\n",
            "percentage of trainable model parameters: 0.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ref_model = create_reference_model(ppo_model)\n",
        "\n",
        "print(f'Reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bfdf1f7-3509-4adc-812a-2b22bd330137",
      "metadata": {
        "id": "4bfdf1f7-3509-4adc-812a-2b22bd330137"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "### 2.2 - Reward Model\n",
        "[Meta AI's RoBERTa-based hate speech model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target) for the reward model. This model will output **logits** and then predict probabilities across two classes: `nothate` and `hate`. The logits of the output `nothate` will be taken as a positive reward. Then, the model will be fine-tuned with PPO using those reward values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f038a9f-e04b-49bc-8923-8ef3816919ee",
      "metadata": {
        "tags": [],
        "id": "7f038a9f-e04b-49bc-8923-8ef3816919ee",
        "outputId": "97084e1b-ec5b-4078-80fa-154dc033037c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'nothate', 1: 'hate'}\n"
          ]
        }
      ],
      "source": [
        "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
        "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
        "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
        "print(toxicity_model.config.id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4e6a05-2398-4ca7-a176-d5a1ff27fe39",
      "metadata": {
        "tags": [],
        "id": "8f4e6a05-2398-4ca7-a176-d5a1ff27fe39",
        "outputId": "4ea2e784-3b46-48dc-a8e4-5e62aec0f79c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[128], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m non_toxic_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#Person 1# tells Tommy that he didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt like the movie.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m toxicity_input_ids \u001b[38;5;241m=\u001b[39m toxicity_tokenizer(non_toxic_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m----> 5\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mtoxicity_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoxicity_input_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits [not hate, hate]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print the probabilities for [not hate, hate]\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:828\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    836\u001b[0m     embedding_output,\n\u001b[0;32m    837\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    845\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    846\u001b[0m )\n\u001b[0;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:125\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    122\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    128\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ],
      "source": [
        "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
        "\n",
        "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
        "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
        "\n",
        "# Print the probabilities for [not hate, hate]\n",
        "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
        "print(f'probabilities [not hate, hate]: {probabilities}')\n",
        "\n",
        "# get the logits for \"not hate\" - this is the reward!\n",
        "not_hate_index = 0\n",
        "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
        "print(f'reward (high): {nothate_reward}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ffc81e4-b220-4f4e-95ec-98ac418612d1",
      "metadata": {
        "tags": [],
        "id": "0ffc81e4-b220-4f4e-95ec-98ac418612d1",
        "outputId": "563d37b8-df75-46f1-bf1f-ddb0c457fbc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[129], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m toxic_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m toxicity_input_ids \u001b[38;5;241m=\u001b[39m toxicity_tokenizer(toxic_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m----> 5\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mtoxicity_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoxicity_input_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits [not hate, hate]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print the probabilities for [not hate, hate]\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:828\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    836\u001b[0m     embedding_output,\n\u001b[0;32m    837\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    845\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    846\u001b[0m )\n\u001b[0;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:125\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    122\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    128\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ],
      "source": [
        "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
        "\n",
        "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "logits = toxicity_model(toxicity_input_ids).logits\n",
        "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
        "\n",
        "# Print the probabilities for [not hate, hate]\n",
        "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
        "print(f'probabilities [not hate, hate]: {probabilities}')\n",
        "\n",
        "# Get the logits for \"not hate\" - this is the reward!\n",
        "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
        "print(f'reward (low): {nothate_reward}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6e656e-fefe-4623-8bbb-472a8cf1c3c5",
      "metadata": {
        "id": "bc6e656e-fefe-4623-8bbb-472a8cf1c3c5"
      },
      "source": [
        "Setup Hugging Face inference pipeline to simplify the code for the toxicity reward model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73aab8c6-33eb-4bf4-a816-3866fc3460af",
      "metadata": {
        "tags": [],
        "id": "73aab8c6-33eb-4bf4-a816-3866fc3460af",
        "outputId": "f66a8b8f-def7-4e56-d3e4-4cf843ecc2e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward model output:\n",
            "For non-toxic text\n",
            "[{'label': 'nothate', 'score': 3.114102363586426}, {'label': 'hate', 'score': -2.489619016647339}]\n",
            "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706042010337114}]\n",
            "For toxic text\n",
            "[{'label': 'hate', 'score': 0.3722699284553528}, {'label': 'nothate', 'score': -0.6921154856681824}]\n",
            "[{'label': 'hate', 'score': 0.7435277700424194}, {'label': 'nothate', 'score': 0.25647228956222534}]\n"
          ]
        }
      ],
      "source": [
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "sentiment_pipe = pipeline(\"sentiment-analysis\",\n",
        "                          model=toxicity_model_name,\n",
        "                          device=device)\n",
        "reward_logits_kwargs = {\n",
        "    \"top_k\": None, # Return all scores.\n",
        "    \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\n",
        "    \"batch_size\": 16\n",
        "}\n",
        "\n",
        "reward_probabilities_kwargs = {\n",
        "    \"top_k\": None, # Return all scores.\n",
        "    \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\n",
        "    \"batch_size\": 16\n",
        "}\n",
        "\n",
        "print(\"Reward model output:\")\n",
        "print(\"For non-toxic text\")\n",
        "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
        "print(\"For toxic text\")\n",
        "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36ff3925-70c4-495c-ae26-68e2fc36296b",
      "metadata": {
        "id": "36ff3925-70c4-495c-ae26-68e2fc36296b",
        "outputId": "96e79162-8c9a-42af-aaf5-d2ecbbb33692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'nothate', 'score': 3.114102363586426}, {'label': 'hate', 'score': -2.489619016647339}]\n",
            "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706042010337114}]\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d11618b-5887-489a-b390-2139e364987f",
      "metadata": {
        "id": "8d11618b-5887-489a-b390-2139e364987f",
        "outputId": "22ed0793-9527-4909-967b-281dc30a2315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'hate', 'score': 0.3722699284553528}, {'label': 'nothate', 'score': -0.6921154856681824}]\n",
            "[{'label': 'hate', 'score': 0.7435277700424194}, {'label': 'nothate', 'score': 0.25647228956222534}]\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56513033-9bb1-41d5-81e2-54d1249c5c89",
      "metadata": {
        "tags": [],
        "id": "56513033-9bb1-41d5-81e2-54d1249c5c89"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "### 2.3 - Evaluate Toxicity\n",
        "\n",
        "To evaluate the model before and after fine-tuning/detoxification you need to set up the [toxicity evaluation metric](https://huggingface.co/spaces/evaluate-measurement/toxicity). The **toxicity score** is a decimal value between 0 and 1 where 1 is the highest toxicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7de8e99d-60ea-48a2-bdf5-817f80b48979",
      "metadata": {
        "tags": [],
        "id": "7de8e99d-60ea-48a2-bdf5-817f80b48979"
      },
      "outputs": [],
      "source": [
        "toxicity_evaluator = evaluate.load(\"toxicity\",\n",
        "                                    toxicity_model_name,\n",
        "                                    module_type=\"measurement\",\n",
        "                                    toxic_label=\"hate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5298f91c-30d1-4d17-95a7-553952ac97b5",
      "metadata": {
        "tags": [],
        "id": "5298f91c-30d1-4d17-95a7-553952ac97b5",
        "outputId": "c5c93dc7-40dc-4e10-9263-6b092fef696f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toxicity score for non-toxic text:\n",
            "[0.003670611185953021]\n",
            "\n",
            "Toxicity score for toxic text:\n",
            "[0.7435290813446045]\n"
          ]
        }
      ],
      "source": [
        "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
        "    non_toxic_text\n",
        "])\n",
        "\n",
        "print(\"Toxicity score for non-toxic text:\")\n",
        "print(toxicity_score[\"toxicity\"])\n",
        "\n",
        "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
        "    toxic_text\n",
        "])\n",
        "\n",
        "print(\"\\nToxicity score for toxic text:\")\n",
        "print(toxicity_score[\"toxicity\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316ab128-33ff-4a1e-8936-47bfa29d48a3",
      "metadata": {
        "tags": [],
        "id": "316ab128-33ff-4a1e-8936-47bfa29d48a3"
      },
      "outputs": [],
      "source": [
        "def evaluate_toxicity(model,\n",
        "                      toxicity_evaluator,\n",
        "                      tokenizer,\n",
        "                      dataset,\n",
        "                      num_samples):\n",
        "\n",
        "    \"\"\"\n",
        "    Preprocess the dataset and split it into train and test parts.\n",
        "\n",
        "    Parameters:\n",
        "    - model (trl model): Model to be evaluated.\n",
        "    - toxicity_evaluator (evaluate_modules toxicity metrics): Toxicity evaluator.\n",
        "    - tokenizer (transformers tokenizer): Tokenizer to be used.\n",
        "    - dataset (dataset): Input dataset for the evaluation.\n",
        "    - num_samples (int): Maximum number of samples for the evaluation.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing two numpy.float64 values:\n",
        "    - mean (numpy.float64): Mean of the samples toxicity.\n",
        "    - std (numpy.float64): Standard deviation of the samples toxicity.\n",
        "    \"\"\"\n",
        "\n",
        "    max_new_tokens=100\n",
        "\n",
        "    toxicities = []\n",
        "    input_texts = []\n",
        "    for i, sample in tqdm(enumerate(dataset)):\n",
        "        input_text = sample[\"query\"]\n",
        "\n",
        "        if i > num_samples:\n",
        "            break\n",
        "\n",
        "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids.to('cuda')\n",
        "\n",
        "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
        "                                             tok_k=0.0,\n",
        "                                             top_p=1.0,\n",
        "                                             do_sample=True)\n",
        "\n",
        "        response_token_ids = model.generate(input_ids=input_ids,\n",
        "                                            generation_config=generation_config)\n",
        "\n",
        "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
        "\n",
        "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
        "\n",
        "    # Compute mean & std using np.\n",
        "    mean = np.mean(toxicities)\n",
        "    std = np.std(toxicities)\n",
        "\n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11ede15-dc1a-4a7e-a60d-b9cadfc7d876",
      "metadata": {
        "tags": [],
        "id": "c11ede15-dc1a-4a7e-a60d-b9cadfc7d876",
        "outputId": "ad69eb95-aefb-4416-8058-416e6aba13d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11it [00:15,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxicity [mean, std] before detox: [0.03754109977109527, 0.045876143852681836]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
        "\n",
        "ref_model.to('cuda')\n",
        "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model,\n",
        "                                                                          toxicity_evaluator=toxicity_evaluator,\n",
        "                                                                          tokenizer=tokenizer,\n",
        "                                                                          dataset=dataset[\"test\"],\n",
        "                                                                          num_samples=10)\n",
        "\n",
        "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba81c90-1ac8-4403-ac1a-d4c75c6df4f0",
      "metadata": {
        "id": "1ba81c90-1ac8-4403-ac1a-d4c75c6df4f0"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Perform Fine-Tuning to Detoxify the Summaries\n",
        "Optimize a RL policy against the reward model using Proximal Policy Optimization (PPO)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5516e318-8fce-4ca7-bf19-b7baf5255480",
      "metadata": {
        "id": "5516e318-8fce-4ca7-bf19-b7baf5255480"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "### 3.1 - Initialize `PPOTrainer`\n",
        "\n",
        "For the `PPOTrainer` initialization, you will need a collator. Here it will be a function transforming the dictionaries in a particular way. You can define and test it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b7be1c0-382a-4fe2-8174-470f3e333e84",
      "metadata": {
        "id": "8b7be1c0-382a-4fe2-8174-470f3e333e84",
        "outputId": "cf57345f-523e-42f6-e4f9-e6819ef2ff29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
            "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
          ]
        }
      ],
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
        "\n",
        "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
        "print(f'Collator input: {test_data}')\n",
        "print(f'Collator output: {collator(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "080c2e92-4988-4944-8353-0e1bb2048072",
      "metadata": {
        "id": "080c2e92-4988-4944-8353-0e1bb2048072"
      },
      "source": [
        "Set up the configuration parameters. Load the `ppo_model` and the tokenizer. You will also load a frozen version of the model `ref_model`. The first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This works as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494e09a1-9024-4f38-91eb-d73cdc3239e6",
      "metadata": {
        "id": "494e09a1-9024-4f38-91eb-d73cdc3239e6"
      },
      "outputs": [],
      "source": [
        "learning_rate=1.41e-5\n",
        "max_ppo_epochs=1\n",
        "mini_batch_size=4\n",
        "batch_size=16\n",
        "\n",
        "config = PPOConfig(\n",
        "    model_name=model_name,\n",
        "    learning_rate=learning_rate,\n",
        "    ppo_epochs=max_ppo_epochs,\n",
        "    mini_batch_size=mini_batch_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "ppo_trainer = PPOTrainer(config=config,\n",
        "                         model=ppo_model,\n",
        "                         ref_model=ref_model,\n",
        "                         tokenizer=tokenizer,\n",
        "                         dataset=dataset[\"train\"],\n",
        "                         data_collator=collator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ad77d2c-3800-4e15-bb38-3851d94ad374",
      "metadata": {
        "id": "7ad77d2c-3800-4e15-bb38-3851d94ad374"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "### 3.2 - Fine-Tune the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cac21fb-fea5-4e80-a741-87f35ae72c62",
      "metadata": {
        "id": "0cac21fb-fea5-4e80-a741-87f35ae72c62"
      },
      "source": [
        "The fine-tuning loop consists of the following main steps:\n",
        "1. Get the query responses from the policy LLM (PEFT model).\n",
        "2. Get sentiments for query/responses from hate speech RoBERTa model.\n",
        "3. Optimize policy with PPO using the (query, response, reward) triplet.\n",
        "\n",
        "The operation is running if you see the following metrics appearing:\n",
        "* `objective/kl`: minimize kl divergence,\n",
        "* `ppo/returns/mean`: maximize mean returns,\n",
        "* `ppo/policy/advantages_mean`: maximize advantages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc55397-92b8-4f61-9ec2-c8b39d5f8962",
      "metadata": {
        "tags": [],
        "id": "4bc55397-92b8-4f61-9ec2-c8b39d5f8962",
        "outputId": "68006cc0-1a88-4352-df74-8d0fc678a4a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:23, 23.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 40.246826171875\n",
            "ppo/returns/mean: -0.9812709093093872\n",
            "ppo/policy/advantages_mean: 0.014773242175579071\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:46, 23.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 45.724876403808594\n",
            "ppo/returns/mean: -1.3616576194763184\n",
            "ppo/policy/advantages_mean: 0.016780545935034752\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [01:07, 22.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 47.26573944091797\n",
            "ppo/returns/mean: -1.3845899105072021\n",
            "ppo/policy/advantages_mean: 0.038513340055942535\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [01:31, 23.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 44.24091339111328\n",
            "ppo/returns/mean: -1.2929332256317139\n",
            "ppo/policy/advantages_mean: -0.0018735788762569427\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [01:47, 20.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 31.330520629882812\n",
            "ppo/returns/mean: -0.5777068138122559\n",
            "ppo/policy/advantages_mean: 0.1567683070898056\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [02:07, 20.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 34.8398551940918\n",
            "ppo/returns/mean: -0.6965826153755188\n",
            "ppo/policy/advantages_mean: 0.008452363312244415\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [02:31, 21.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 47.201507568359375\n",
            "ppo/returns/mean: -1.2850310802459717\n",
            "ppo/policy/advantages_mean: 0.0189276821911335\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [02:52, 21.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 51.514137268066406\n",
            "ppo/returns/mean: -1.407408595085144\n",
            "ppo/policy/advantages_mean: 0.04018046334385872\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [03:14, 21.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 45.652950286865234\n",
            "ppo/returns/mean: -1.1277023553848267\n",
            "ppo/policy/advantages_mean: 0.010566985234618187\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10it [03:32, 21.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objective/kl: 37.997352600097656\n",
            "ppo/returns/mean: -0.9162862300872803\n",
            "ppo/policy/advantages_mean: 0.03410504013299942\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "output_min_length = 100\n",
        "output_max_length = 400\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
        "\n",
        "generation_kwargs = {\n",
        "    \"min_length\": 5,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True\n",
        "}\n",
        "\n",
        "reward_kwargs = {\n",
        "    \"top_k\": None, # Return all scores.\n",
        "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
        "    \"batch_size\": 16\n",
        "}\n",
        "\n",
        "max_ppo_steps = 10\n",
        "\n",
        "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    # Break when you reach max_steps.\n",
        "    if step >= max_ppo_steps:\n",
        "        break\n",
        "\n",
        "    prompt_tensors = batch[\"input_ids\"]\n",
        "\n",
        "    # Get response from FLAN-T5/PEFT LLM.\n",
        "    summary_tensors = []\n",
        "\n",
        "    for prompt_tensor in prompt_tensors:\n",
        "        max_new_tokens = output_length_sampler()\n",
        "\n",
        "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
        "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
        "\n",
        "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
        "\n",
        "    # This needs to be called \"response\".\n",
        "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
        "\n",
        "    # Compute reward outputs.\n",
        "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
        "\n",
        "    # You use the `nothate` item because this is the score for the positive `nothate` class.\n",
        "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]\n",
        "\n",
        "    # Run PPO step.\n",
        "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
        "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
        "\n",
        "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
        "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
        "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
        "    print('-'.join('' for x in range(100)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7903f5df-a9de-41eb-b239-38bc367b5654",
      "metadata": {
        "id": "7903f5df-a9de-41eb-b239-38bc367b5654"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "### 3.3 - Evaluate the Model Quantitatively\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After PPO"
      ],
      "metadata": {
        "id": "6T4s5MJbfee-"
      },
      "id": "6T4s5MJbfee-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b093d43-6197-4cc0-b933-29030479a7d0",
      "metadata": {
        "tags": [],
        "id": "3b093d43-6197-4cc0-b933-29030479a7d0",
        "outputId": "487efffc-bdce-42ed-9e8d-9c0c8d1747c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11it [00:20,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxicity [mean, std] after detox: [0.03174176426943053, 0.04092620289285807]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model,\n",
        "                                                                        toxicity_evaluator=toxicity_evaluator,\n",
        "                                                                        tokenizer=tokenizer,\n",
        "                                                                        dataset=dataset[\"test\"],\n",
        "                                                                        num_samples=10)\n",
        "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42895cc-7bbf-45e1-a7c7-78ee29cd8009",
      "metadata": {
        "tags": [],
        "id": "f42895cc-7bbf-45e1-a7c7-78ee29cd8009"
      },
      "source": [
        "Improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77cc3af2-6600-4673-874b-917c05247ae3",
      "metadata": {
        "id": "77cc3af2-6600-4673-874b-917c05247ae3",
        "outputId": "c1d2ec36-8255-4b83-c013-2830bca86676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage improvement of toxicity score after detoxification:\n",
            "mean: 15.45%\n",
            "std: 10.79%\n"
          ]
        }
      ],
      "source": [
        "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
        "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
        "\n",
        "print(f'Percentage improvement of toxicity score after detoxification:')\n",
        "print(f'mean: {mean_improvement*100:.2f}%')\n",
        "print(f'std: {std_improvement*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66030581-b6f7-41d7-a7e6-2466226833be",
      "metadata": {
        "id": "66030581-b6f7-41d7-a7e6-2466226833be"
      },
      "source": [
        "<a name='3.4'></a>\n",
        "### 3.4 - Evaluate the Model Qualitatively\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22cc8313-20ae-4d32-855e-9b2866fa3085",
      "metadata": {
        "id": "22cc8313-20ae-4d32-855e-9b2866fa3085",
        "outputId": "02e81b5c-3556-4224-8528-0b4c73661f0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [01:26<00:00,  4.32s/it]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 20\n",
        "compare_results = {}\n",
        "\n",
        "df_batch = dataset[\"test\"][0:batch_size]\n",
        "\n",
        "compare_results[\"query\"] = df_batch[\"query\"]\n",
        "prompt_tensors = df_batch[\"input_ids\"]\n",
        "\n",
        "summary_tensors_ref = []\n",
        "summary_tensors = []\n",
        "\n",
        "# Get response from ppo and base model.\n",
        "for i in tqdm(range(batch_size)):\n",
        "    gen_len = output_length_sampler()\n",
        "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
        "\n",
        "    summary = ref_model.generate(\n",
        "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "        **generation_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    summary_tensors_ref.append(summary)\n",
        "\n",
        "    summary = ppo_model.generate(\n",
        "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "        **generation_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    summary_tensors.append(summary)\n",
        "\n",
        "# Decode responses.\n",
        "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
        "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
        "\n",
        "# Sentiment analysis of query/response pairs before/after.\n",
        "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
        "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
        "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
        "\n",
        "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
        "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
        "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e06fff0f-9dba-4517-9424-a5ebd81e8f49",
      "metadata": {
        "tags": [],
        "id": "e06fff0f-9dba-4517-9424-a5ebd81e8f49",
        "outputId": "41b3db01-0c5f-4d50-866c-904b746de24b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>response_before</th>\n",
              "      <th>response_after</th>\n",
              "      <th>reward_before</th>\n",
              "      <th>reward_after</th>\n",
              "      <th>reward_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...</td>\n",
              "      <td>&lt;pad&gt; Allen has broken into the house and one of his things was stolen. Allen's mind stops and recognizes the only thing the robber stole. Allen will go to the windows.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Allen and #Person1# are concerned about what a robber stole, though they don't think there will be one alive. Allen had a picture of the bird but the bird locked it and made the bird flee, which he found through the door then not locked at all.&lt;/s&gt;</td>\n",
              "      <td>1.577376</td>\n",
              "      <td>2.092901</td>\n",
              "      <td>0.515524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: &lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Judy and her boss are surprised that Richard was fired. So, Judy and #Person2# think it's true.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Judy and Judy understand Richard was fired. Judy is surprised because everybody is talking about it in the company.&lt;/s&gt;</td>\n",
              "      <td>0.998530</td>\n",
              "      <td>1.466953</td>\n",
              "      <td>0.468423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: &lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# asks #Person2# about mom's imprint essay. #Person1# got excellent ideas from #Person1#'s mom. #Person2# thinks it was worth all the time.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Mother lends her a paper proofread before handing it in. It has been a hard one, but Mom shows sarcastic displeasure.&lt;/s&gt;</td>\n",
              "      <td>2.231749</td>\n",
              "      <td>2.643997</td>\n",
              "      <td>0.412248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: &lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# doesn't know her flight is running and she cannot get someone to help her.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# says everyone else has picked up the luggage but their flight got into 15 minutes ago.&lt;/s&gt;</td>\n",
              "      <td>1.835569</td>\n",
              "      <td>2.229936</td>\n",
              "      <td>0.394368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...</td>\n",
              "      <td>&lt;pad&gt; #Person1# tells #Person2# how the entire people have personal computers. After a successful test of units by a customer, #Person2# can buy goods through the computer without going to the physical stores. #Person2# tells #Person1# in detail how the computer can be used to buy goods.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# shows some examples of the uses of a PC. Takes a lesson from PC for people to buy some groceries by relying on the web and connects to the sales company. She tells #Person2# how she can place an order online and enjoys the service because the deliver is free.&lt;/s&gt;</td>\n",
              "      <td>2.635307</td>\n",
              "      <td>2.945903</td>\n",
              "      <td>0.310597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...</td>\n",
              "      <td>&lt;pad&gt; #Person2# tells #Person1# that they still have a good agreement on almost every term in their trade. #Person1# shows #Person2# the final draft with photos of every detail. #Person2# will sign the contract now.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# has briefed #Person1# about outstanding terms and approaches the final draft. They have brought up points in the final draft. They have several days to finish their notes on the terms and defects; therefore they want to sign the contract now.&lt;/s&gt;</td>\n",
              "      <td>3.081573</td>\n",
              "      <td>3.372005</td>\n",
              "      <td>0.290432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...</td>\n",
              "      <td>&lt;pad&gt; #Person1# is buying DEL and converts #Person1#'s football to a DEL relay or dial-up internet. #Person2# thinks DEL is not connected through a phone line, but dial-up is.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# the best Internet is DEL. It means it isn't connected beyond the phone line. Since DEL isn't connected through the phone line, it's still possible to use a phone when using DEL.&lt;/s&gt;</td>\n",
              "      <td>2.184070</td>\n",
              "      <td>2.379267</td>\n",
              "      <td>0.195198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...</td>\n",
              "      <td>&lt;pad&gt; #Person1# wants to do directions to the Cross Bakery yet #Person2# tells her the opposite direction to get there. #Person1# begins at Broadway and meets the Cross Bakery building. #Person2# will show #Person1# a way&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# asks for #Person2#'s directions and asks for the direction on which to get to the Bakery. #Person2# offers #Person1# an extended trip by subway.&lt;/s&gt;</td>\n",
              "      <td>2.654602</td>\n",
              "      <td>2.839283</td>\n",
              "      <td>0.184682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: &lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# offers to buy a cheap car new. #Person2# offers a discount if #Person1# buys more than 1,000 items.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# buys a bird for 150 yuan per piece and will get 10% discount if purchase more than 1 000 of a piece.&lt;/s&gt;</td>\n",
              "      <td>2.325330</td>\n",
              "      <td>2.508447</td>\n",
              "      <td>0.183116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: &lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# wants to buy a toy car for her son. They lose it because it's too expensive. #Person1# helps to find it for her and helps #Person2# pay the price.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# wants to sell a toy car for her son. #Person1# recommends one hundred and twenty dollars and offers it to #Person2#.&lt;/s&gt;</td>\n",
              "      <td>1.195809</td>\n",
              "      <td>1.301500</td>\n",
              "      <td>0.105691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...</td>\n",
              "      <td>&lt;pad&gt; #Person1# asks #Person2# to help look for a job. #Person2# recommends #Person1# to see a job counselor, but #Person1# doesn't think #Person1# need to do that.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# asks #Person2# about using the job center and how to find a job. #Person2# helped #Person1# with shoplifting in the same location and timely within the company.&lt;/s&gt;</td>\n",
              "      <td>2.113558</td>\n",
              "      <td>2.147066</td>\n",
              "      <td>0.033508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...</td>\n",
              "      <td>&lt;pad&gt; #Person1# invites #Person2# to have a coffee break enjoying the fast pace of work, unlike #Person2# who is still too busy to do much work afterwards.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# wants to take a coffee, but #Person2# can't take a break because he's up to his neck in work. #Person1# explained that #Person2# would feel better if they took a break.&lt;/s&gt;</td>\n",
              "      <td>1.959802</td>\n",
              "      <td>1.826756</td>\n",
              "      <td>-0.133046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: &lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Amanda likes going for top hats but #Person2# doesn't want to buy caps.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Amanda doesn't like a cap but she likes this one because it fits her well.&lt;/s&gt;</td>\n",
              "      <td>1.396727</td>\n",
              "      <td>1.256419</td>\n",
              "      <td>-0.140307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...</td>\n",
              "      <td>&lt;pad&gt; #Person2# invites #Person1# to a clinic. #Person1# tells #Person2# the visiting hours is 11:00 GMT and #Person1# pays for the registration.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# registers his information for the surgery for #Person1#. #Person2# wants to make a medical record and describes the terms of treatment. #Person1# will go down this way and see the doctor.&lt;/s&gt;</td>\n",
              "      <td>1.620430</td>\n",
              "      <td>1.424039</td>\n",
              "      <td>-0.196391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: &lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; The cash for #Person1# was cashed with $10s and twenties in small change. #Person1# is satisfied with the cash and chooses to change it.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# is shopping for cash and helps #Person1# to get ten hundreds and ten twenties bills.&lt;/s&gt;</td>\n",
              "      <td>1.972783</td>\n",
              "      <td>1.769356</td>\n",
              "      <td>-0.203427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...</td>\n",
              "      <td>&lt;pad&gt; #Person1# asks #Person2# how the restaurant was and calls in a rating.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# loved the restaurant but it's a new one and service wasn't very good. #Person2# was angry with the restaurant because it's new and it's not good.&lt;/s&gt;</td>\n",
              "      <td>2.401509</td>\n",
              "      <td>2.186926</td>\n",
              "      <td>-0.214583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...</td>\n",
              "      <td>&lt;pad&gt; #Person1# wants to confirm their flight for tomorrow at 1 p.m. #Person2# calls '35' so #Person1# can call the airline office to confirm the data. #Person1# has just dialed 135.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; The airline can't tell #Person1# how to get the flight to London from #Person2#'s office.&lt;/s&gt;</td>\n",
              "      <td>1.978626</td>\n",
              "      <td>1.759486</td>\n",
              "      <td>-0.219140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...</td>\n",
              "      <td>&lt;pad&gt; #Person1# wants to form a rock band after learning to play the drums. #Person2# invites #Person1# to audition at #Person1#'s house this weekend, because #Person1# doesn't have enough space for the amplifiers, microphones, and even the drums. #Person1#'s music talent is enough so #Person2# can audition this weekend.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# wants to start a music band and wants to do so when he realizes there's no singer. #Person1# decides to audition but the audition is at #Person1#'s home.&lt;/s&gt;</td>\n",
              "      <td>2.767497</td>\n",
              "      <td>2.376706</td>\n",
              "      <td>-0.390790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...</td>\n",
              "      <td>&lt;pad&gt; Alice can't visit Mrs. Brown tomorrow morning, because her mother is ill. Li Hong and Alice meet for a visit.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Alice can't join Li Hong because her mother is ill. Li Hong suggests Si Leung to stay at home.&lt;/s&gt;</td>\n",
              "      <td>2.150470</td>\n",
              "      <td>1.183595</td>\n",
              "      <td>-0.966874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...</td>\n",
              "      <td>&lt;pad&gt; #Person1# shows #Person2# a fresh look of nervousness on #Person2#'s face. They know there's some other ways to quit but #Person2# has no idea how to quit because people spend more money on cigarettes every month, as coffee shop is on its way with the restrictions.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Holly thinks she smells like an ashtray and wants a divorce, but she knows 60 minutes take till she quits smoking.&lt;/s&gt;</td>\n",
              "      <td>2.479597</td>\n",
              "      <td>1.200324</td>\n",
              "      <td>-1.279273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
              "0   Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...   \n",
              "1                                                                                                                                                                   Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: </s>   \n",
              "2                       Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: </s>   \n",
              "3                                                                                                                                                                                                                                         Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: </s>   \n",
              "4   Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...   \n",
              "5   Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...   \n",
              "6   Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...   \n",
              "7   Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...   \n",
              "8                                                                                     Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: </s>   \n",
              "9           Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: </s>   \n",
              "10  Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...   \n",
              "11  Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...   \n",
              "12                                                                                                                                                                                                                          Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: </s>   \n",
              "13  Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...   \n",
              "14                                                                                                                                                                        Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: </s>   \n",
              "15  Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...   \n",
              "16  Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...   \n",
              "17  Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...   \n",
              "18  Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...   \n",
              "19  Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                           response_before  \\\n",
              "0                                                                                                                                                             <pad> Allen has broken into the house and one of his things was stolen. Allen's mind stops and recognizes the only thing the robber stole. Allen will go to the windows.</s>   \n",
              "1                                                                                                                                                                                                                                <pad> Judy and her boss are surprised that Richard was fired. So, Judy and #Person2# think it's true.</s>   \n",
              "2                                                                                                                                                                            <pad> #Person1# asks #Person2# about mom's imprint essay. #Person1# got excellent ideas from #Person1#'s mom. #Person2# thinks it was worth all the time.</s>   \n",
              "3                                                                                                                                                                                                                                           <pad> #Person1# doesn't know her flight is running and she cannot get someone to help her.</s>   \n",
              "4                                     <pad> #Person1# tells #Person2# how the entire people have personal computers. After a successful test of units by a customer, #Person2# can buy goods through the computer without going to the physical stores. #Person2# tells #Person1# in detail how the computer can be used to buy goods.</s>   \n",
              "5                                                                                                              <pad> #Person2# tells #Person1# that they still have a good agreement on almost every term in their trade. #Person1# shows #Person2# the final draft with photos of every detail. #Person2# will sign the contract now.</s>   \n",
              "6                                                                                                                                                      <pad> #Person1# is buying DEL and converts #Person1#'s football to a DEL relay or dial-up internet. #Person2# thinks DEL is not connected through a phone line, but dial-up is.</s>   \n",
              "7                                                                                                        <pad> #Person1# wants to do directions to the Cross Bakery yet #Person2# tells her the opposite direction to get there. #Person1# begins at Broadway and meets the Cross Bakery building. #Person2# will show #Person1# a way</s>   \n",
              "8                                                                                                                                                                                                                  <pad> #Person1# offers to buy a cheap car new. #Person2# offers a discount if #Person1# buys more than 1,000 items.</s>   \n",
              "9                                                                                                                                                                   <pad> #Person2# wants to buy a toy car for her son. They lose it because it's too expensive. #Person1# helps to find it for her and helps #Person2# pay the price.</s>   \n",
              "10                                                                                                                                                                <pad> #Person1# asks #Person2# to help look for a job. #Person2# recommends #Person1# to see a job counselor, but #Person1# doesn't think #Person1# need to do that.</s>   \n",
              "11                                                                                                                                                                         <pad> #Person1# invites #Person2# to have a coffee break enjoying the fast pace of work, unlike #Person2# who is still too busy to do much work afterwards.</s>   \n",
              "12                                                                                                                                                                                                                                                       <pad> Amanda likes going for top hats but #Person2# doesn't want to buy caps.</s>   \n",
              "13                                                                                                                                                                                   <pad> #Person2# invites #Person1# to a clinic. #Person1# tells #Person2# the visiting hours is 11:00 GMT and #Person1# pays for the registration.</s>   \n",
              "14                                                                                                                                                                                      <pad> The cash for #Person1# was cashed with $10s and twenties in small change. #Person1# is satisfied with the cash and chooses to change it.</s>   \n",
              "15                                                                                                                                                                                                                                                        <pad> #Person1# asks #Person2# how the restaurant was and calls in a rating.</s>   \n",
              "16                                                                                                                                              <pad> #Person1# wants to confirm their flight for tomorrow at 1 p.m. #Person2# calls '35' so #Person1# can call the airline office to confirm the data. #Person1# has just dialed 135.</s>   \n",
              "17  <pad> #Person1# wants to form a rock band after learning to play the drums. #Person2# invites #Person1# to audition at #Person1#'s house this weekend, because #Person1# doesn't have enough space for the amplifiers, microphones, and even the drums. #Person1#'s music talent is enough so #Person2# can audition this weekend.</s>   \n",
              "18                                                                                                                                                                                                                 <pad> Alice can't visit Mrs. Brown tomorrow morning, because her mother is ill. Li Hong and Alice meet for a visit.</s>   \n",
              "19                                                     <pad> #Person1# shows #Person2# a fresh look of nervousness on #Person2#'s face. They know there's some other ways to quit but #Person2# has no idea how to quit because people spend more money on cigarettes every month, as coffee shop is on its way with the restrictions.</s>   \n",
              "\n",
              "                                                                                                                                                                                                                                                                             response_after  \\\n",
              "0                            <pad> Allen and #Person1# are concerned about what a robber stole, though they don't think there will be one alive. Allen had a picture of the bird but the bird locked it and made the bird flee, which he found through the door then not locked at all.</s>   \n",
              "1                                                                                                                                                             <pad> Judy and Judy understand Richard was fired. Judy is surprised because everybody is talking about it in the company.</s>   \n",
              "2                                                                                                                                                           <pad> Mother lends her a paper proofread before handing it in. It has been a hard one, but Mom shows sarcastic displeasure.</s>   \n",
              "3                                                                                                                                                                                <pad> #Person1# says everyone else has picked up the luggage but their flight got into 15 minutes ago.</s>   \n",
              "4   <pad> #Person1# shows some examples of the uses of a PC. Takes a lesson from PC for people to buy some groceries by relying on the web and connects to the sales company. She tells #Person2# how she can place an order online and enjoys the service because the deliver is free.</s>   \n",
              "5                    <pad> #Person2# has briefed #Person1# about outstanding terms and approaches the final draft. They have brought up points in the final draft. They have several days to finish their notes on the terms and defects; therefore they want to sign the contract now.</s>   \n",
              "6                                                                                     <pad> #Person2# the best Internet is DEL. It means it isn't connected beyond the phone line. Since DEL isn't connected through the phone line, it's still possible to use a phone when using DEL.</s>   \n",
              "7                                                                                                                      <pad> #Person1# asks for #Person2#'s directions and asks for the direction on which to get to the Bakery. #Person2# offers #Person1# an extended trip by subway.</s>   \n",
              "8                                                                                                                                                                  <pad> #Person1# buys a bird for 150 yuan per piece and will get 10% discount if purchase more than 1 000 of a piece.</s>   \n",
              "9                                                                                                                                                  <pad> #Person1# wants to sell a toy car for her son. #Person1# recommends one hundred and twenty dollars and offers it to #Person2#.</s>   \n",
              "10                                                                                                     <pad> #Person1# asks #Person2# about using the job center and how to find a job. #Person2# helped #Person1# with shoplifting in the same location and timely within the company.</s>   \n",
              "11                                                                                             <pad> #Person1# wants to take a coffee, but #Person2# can't take a break because he's up to his neck in work. #Person1# explained that #Person2# would feel better if they took a break.</s>   \n",
              "12                                                                                                                                                                                                     <pad> Amanda doesn't like a cap but she likes this one because it fits her well.</s>   \n",
              "13                                                                          <pad> #Person2# registers his information for the surgery for #Person1#. #Person2# wants to make a medical record and describes the terms of treatment. #Person1# will go down this way and see the doctor.</s>   \n",
              "14                                                                                                                                                                                 <pad> #Person2# is shopping for cash and helps #Person1# to get ten hundreds and ten twenties bills.</s>   \n",
              "15                                                                                                                    <pad> #Person2# loved the restaurant but it's a new one and service wasn't very good. #Person2# was angry with the restaurant because it's new and it's not good.</s>   \n",
              "16                                                                                                                                                                                      <pad> The airline can't tell #Person1# how to get the flight to London from #Person2#'s office.</s>   \n",
              "17                                                                                                            <pad> #Person1# wants to start a music band and wants to do so when he realizes there's no singer. #Person1# decides to audition but the audition is at #Person1#'s home.</s>   \n",
              "18                                                                                                                                                                                 <pad> Alice can't join Li Hong because her mother is ill. Li Hong suggests Si Leung to stay at home.</s>   \n",
              "19                                                                                                                                                             <pad> Holly thinks she smells like an ashtray and wants a divorce, but she knows 60 minutes take till she quits smoking.</s>   \n",
              "\n",
              "    reward_before  reward_after  reward_diff  \n",
              "0        1.577376      2.092901     0.515524  \n",
              "1        0.998530      1.466953     0.468423  \n",
              "2        2.231749      2.643997     0.412248  \n",
              "3        1.835569      2.229936     0.394368  \n",
              "4        2.635307      2.945903     0.310597  \n",
              "5        3.081573      3.372005     0.290432  \n",
              "6        2.184070      2.379267     0.195198  \n",
              "7        2.654602      2.839283     0.184682  \n",
              "8        2.325330      2.508447     0.183116  \n",
              "9        1.195809      1.301500     0.105691  \n",
              "10       2.113558      2.147066     0.033508  \n",
              "11       1.959802      1.826756    -0.133046  \n",
              "12       1.396727      1.256419    -0.140307  \n",
              "13       1.620430      1.424039    -0.196391  \n",
              "14       1.972783      1.769356    -0.203427  \n",
              "15       2.401509      2.186926    -0.214583  \n",
              "16       1.978626      1.759486    -0.219140  \n",
              "17       2.767497      2.376706    -0.390790  \n",
              "18       2.150470      1.183595    -0.966874  \n",
              "19       2.479597      1.200324    -1.279273  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', 500)\n",
        "df_compare_results = pd.DataFrame(compare_results)\n",
        "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
        "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
        "df_compare_results_sorted"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7fb2477-f719-48de-b169-0607d355a8f6",
      "metadata": {
        "id": "e7fb2477-f719-48de-b169-0607d355a8f6"
      },
      "source": [
        "Looking at the reward mean/median of the generated sequences you can observe a significant difference!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4a19dd-ef86-41a9-8937-9c1d1494ac62",
      "metadata": {
        "id": "df4a19dd-ef86-41a9-8937-9c1d1494ac62"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "instance_type": "ml.m5.2xlarge",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}